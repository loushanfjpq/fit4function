{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9ba5c5-ea9a-4cdc-a15f-3a9a82a692d0",
   "metadata": {},
   "source": [
    "# MultiFunction Library Modeling and Validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794f5586-7cbe-4a0d-b920-b4c0aa024822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Suppress the warning    \n",
    "\n",
    "from utils_f4f import CustomEarlyStopping, AA_hotencoding, parent_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3919884-8404-4c59-8526-b995f43411c3",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# MultiFunction Modeling and Validation of individual assays \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89dee2a3-3fdf-4bf2-ba02-4f88a118508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            AA  Production1  Production2     Liver  HepG2_bind  HepG2_tr  \\\n",
      "0      AAAARFE     0.487790    -0.086382 -0.444430   -2.011627 -0.800518   \n",
      "1      AAAETST    -1.377736     0.003127 -3.680569   -2.042271      -inf   \n",
      "2      AAAFDHK    -1.236781    -1.502219 -0.494197   -1.903524      -inf   \n",
      "3      AAAFEVL    -2.534514    -3.331298 -0.027308   -1.696997      -inf   \n",
      "4      AAAKDTY    -0.457144     1.485808 -2.042368   -1.956978 -1.963174   \n",
      "...        ...          ...          ...       ...         ...       ...   \n",
      "99995  YYVKARD    -0.916975    -1.554667  1.684322    3.245247  5.231389   \n",
      "99996  YYVRSDK    -4.413469    -5.286344  1.511374        -inf      -inf   \n",
      "99997  YYVSNSN    -5.114956    -5.878805  1.082656        -inf      -inf   \n",
      "99998  YYVSPHE    -1.206143    -2.498700 -0.669647        -inf  0.518604   \n",
      "99999  YYYQEVE    -5.401841    -5.481131 -1.316135        -inf      -inf   \n",
      "\n",
      "       THLE_bind   THLE_tr  \n",
      "0      -1.284821 -4.404453  \n",
      "1      -3.369956 -1.411144  \n",
      "2      -2.076384 -4.029246  \n",
      "3      -0.720355      -inf  \n",
      "4      -1.799738 -1.552933  \n",
      "...          ...       ...  \n",
      "99995   2.047146  3.701003  \n",
      "99996   1.042864      -inf  \n",
      "99997        NaN       NaN  \n",
      "99998  -0.793042      -inf  \n",
      "99999        NaN       NaN  \n",
      "\n",
      "[100000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "assays_F4F =  pd.read_csv('data/fit4function_library_screens.csv')\n",
    "print(assays_F4F)\n",
    "assays = ['Production2', 'HepG2_bind', 'THLE_bind','HepG2_tr' , 'THLE_tr','Liver'];\n",
    "\n",
    "#Training data \n",
    "train_dfs = dict()\n",
    "for crnt_assay in assays:\n",
    "    crnt_df = assays_F4F[['AA',crnt_assay]]\n",
    "    crnt_df['Output'] = crnt_df[crnt_assay]\n",
    "    train_dfs[crnt_assay] = crnt_df[['AA','Output']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b18ac73-c7bb-4d4a-8da5-b70471b63e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training:  Production2\n",
      "Epoch 1/20\n",
      "158/158 - 4s - loss: 2.5191 - mae: 1.2157 - val_loss: 2.0796 - val_mae: 1.0756 - 4s/epoch - 28ms/step\n",
      "Epoch 2/20\n",
      "158/158 - 3s - loss: 1.9798 - mae: 1.0630 - val_loss: 1.9065 - val_mae: 1.0204 - 3s/epoch - 22ms/step\n",
      "Epoch 3/20\n",
      "158/158 - 4s - loss: 1.8464 - mae: 1.0208 - val_loss: 1.8160 - val_mae: 1.0211 - 4s/epoch - 23ms/step\n",
      "Epoch 4/20\n",
      "158/158 - 4s - loss: 1.7496 - mae: 0.9875 - val_loss: 1.7880 - val_mae: 1.0131 - 4s/epoch - 25ms/step\n",
      "Epoch 5/20\n",
      "158/158 - 4s - loss: 1.6894 - mae: 0.9655 - val_loss: 1.6948 - val_mae: 0.9480 - 4s/epoch - 26ms/step\n",
      "Epoch 6/20\n",
      "158/158 - 4s - loss: 1.6529 - mae: 0.9524 - val_loss: 1.6631 - val_mae: 0.9414 - 4s/epoch - 27ms/step\n",
      "Epoch 7/20\n",
      "158/158 - 4s - loss: 1.6300 - mae: 0.9450 - val_loss: 1.6362 - val_mae: 0.9306 - 4s/epoch - 25ms/step\n",
      "Epoch 8/20\n",
      "158/158 - 4s - loss: 1.5951 - mae: 0.9335 - val_loss: 1.6337 - val_mae: 0.9313 - 4s/epoch - 28ms/step\n",
      "Epoch 9/20\n",
      "158/158 - 4s - loss: 1.5778 - mae: 0.9281 - val_loss: 1.6228 - val_mae: 0.9185 - 4s/epoch - 26ms/step\n",
      "Epoch 10/20\n",
      "158/158 - 4s - loss: 1.5632 - mae: 0.9241 - val_loss: 1.5983 - val_mae: 0.9195 - 4s/epoch - 26ms/step\n",
      "Epoch 11/20\n",
      "158/158 - 4s - loss: 1.5444 - mae: 0.9173 - val_loss: 1.6140 - val_mae: 0.9211 - 4s/epoch - 25ms/step\n",
      "Epoch 12/20\n",
      "158/158 - 4s - loss: 1.5330 - mae: 0.9141 - val_loss: 1.5777 - val_mae: 0.9240 - 4s/epoch - 26ms/step\n",
      "Epoch 13/20\n",
      "158/158 - 4s - loss: 1.5233 - mae: 0.9112 - val_loss: 1.5776 - val_mae: 0.9237 - 4s/epoch - 27ms/step\n",
      "Epoch 14/20\n",
      "158/158 - 5s - loss: 1.4985 - mae: 0.9031 - val_loss: 1.5662 - val_mae: 0.9031 - 5s/epoch - 29ms/step\n",
      "Epoch 15/20\n",
      "158/158 - 4s - loss: 1.4893 - mae: 0.9007 - val_loss: 1.5548 - val_mae: 0.9090 - 4s/epoch - 28ms/step\n",
      "Epoch 16/20\n",
      "158/158 - 4s - loss: 1.4645 - mae: 0.8926 - val_loss: 1.5387 - val_mae: 0.9047 - 4s/epoch - 28ms/step\n",
      "Epoch 17/20\n",
      "158/158 - 4s - loss: 1.4575 - mae: 0.8910 - val_loss: 1.5282 - val_mae: 0.9146 - 4s/epoch - 26ms/step\n",
      "Epoch 18/20\n",
      "158/158 - 4s - loss: 1.4424 - mae: 0.8868 - val_loss: 1.5217 - val_mae: 0.9126 - 4s/epoch - 26ms/step\n",
      "Epoch 19/20\n",
      "158/158 - 4s - loss: 1.4294 - mae: 0.8824 - val_loss: 1.5149 - val_mae: 0.9013 - 4s/epoch - 27ms/step\n",
      "Epoch 20/20\n",
      "158/158 - 4s - loss: 1.4200 - mae: 0.8801 - val_loss: 1.5296 - val_mae: 0.9175 - 4s/epoch - 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 1s 2ms/step\n",
      "Currently training:  HepG2_bind\n",
      "Epoch 1/20\n",
      "123/123 - 4s - loss: 2.6899 - mae: 1.2028 - val_loss: 2.0762 - val_mae: 1.0411 - 4s/epoch - 32ms/step\n",
      "Epoch 2/20\n",
      "123/123 - 3s - loss: 1.9350 - mae: 1.0118 - val_loss: 1.7914 - val_mae: 0.9861 - 3s/epoch - 23ms/step\n",
      "Epoch 3/20\n",
      "123/123 - 3s - loss: 1.6962 - mae: 0.9562 - val_loss: 1.6097 - val_mae: 0.9371 - 3s/epoch - 24ms/step\n",
      "Epoch 4/20\n",
      "123/123 - 3s - loss: 1.5821 - mae: 0.9288 - val_loss: 1.5781 - val_mae: 0.9272 - 3s/epoch - 24ms/step\n",
      "Epoch 5/20\n",
      "123/123 - 3s - loss: 1.5231 - mae: 0.9143 - val_loss: 1.4790 - val_mae: 0.9045 - 3s/epoch - 25ms/step\n",
      "Epoch 6/20\n",
      "123/123 - 3s - loss: 1.4781 - mae: 0.9034 - val_loss: 1.4707 - val_mae: 0.9047 - 3s/epoch - 25ms/step\n",
      "Epoch 7/20\n",
      "123/123 - 3s - loss: 1.4403 - mae: 0.8923 - val_loss: 1.4802 - val_mae: 0.9110 - 3s/epoch - 25ms/step\n",
      "Epoch 8/20\n",
      "123/123 - 3s - loss: 1.4359 - mae: 0.8914 - val_loss: 1.4818 - val_mae: 0.9088 - 3s/epoch - 26ms/step\n",
      "Epoch 9/20\n",
      "123/123 - 3s - loss: 1.3914 - mae: 0.8781 - val_loss: 1.3896 - val_mae: 0.8776 - 3s/epoch - 26ms/step\n",
      "Epoch 10/20\n",
      "123/123 - 3s - loss: 1.3771 - mae: 0.8745 - val_loss: 1.4026 - val_mae: 0.8802 - 3s/epoch - 27ms/step\n",
      "Epoch 11/20\n",
      "123/123 - 3s - loss: 1.3591 - mae: 0.8679 - val_loss: 1.3651 - val_mae: 0.8707 - 3s/epoch - 27ms/step\n",
      "Epoch 12/20\n",
      "123/123 - 3s - loss: 1.3609 - mae: 0.8678 - val_loss: 1.3711 - val_mae: 0.8707 - 3s/epoch - 27ms/step\n",
      "Epoch 13/20\n",
      "123/123 - 3s - loss: 1.3497 - mae: 0.8650 - val_loss: 1.3710 - val_mae: 0.8730 - 3s/epoch - 27ms/step\n",
      "Epoch 14/20\n",
      "123/123 - 3s - loss: 1.3324 - mae: 0.8582 - val_loss: 1.3771 - val_mae: 0.8693 - 3s/epoch - 26ms/step\n",
      "Epoch 15/20\n",
      "123/123 - 3s - loss: 1.3256 - mae: 0.8574 - val_loss: 1.3744 - val_mae: 0.8689 - 3s/epoch - 27ms/step\n",
      "Epoch 16/20\n",
      "123/123 - 3s - loss: 1.3163 - mae: 0.8543 - val_loss: 1.3605 - val_mae: 0.8676 - 3s/epoch - 25ms/step\n",
      "Epoch 17/20\n",
      "123/123 - 3s - loss: 1.3110 - mae: 0.8520 - val_loss: 1.3480 - val_mae: 0.8587 - 3s/epoch - 26ms/step\n",
      "Epoch 18/20\n",
      "123/123 - 3s - loss: 1.2954 - mae: 0.8471 - val_loss: 1.3600 - val_mae: 0.8609 - 3s/epoch - 26ms/step\n",
      "Epoch 19/20\n",
      "123/123 - 3s - loss: 1.3021 - mae: 0.8499 - val_loss: 1.3679 - val_mae: 0.8716 - 3s/epoch - 26ms/step\n",
      "Epoch 20/20\n",
      "123/123 - 3s - loss: 1.2896 - mae: 0.8459 - val_loss: 1.3519 - val_mae: 0.8633 - 3s/epoch - 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 1s 2ms/step\n",
      "Currently training:  THLE_bind\n",
      "Epoch 1/20\n",
      "147/147 - 5s - loss: 1.7684 - mae: 0.9764 - val_loss: 1.5062 - val_mae: 0.8973 - 5s/epoch - 33ms/step\n",
      "Epoch 2/20\n",
      "147/147 - 4s - loss: 1.4634 - mae: 0.8626 - val_loss: 1.3446 - val_mae: 0.8134 - 4s/epoch - 24ms/step\n",
      "Epoch 3/20\n",
      "147/147 - 4s - loss: 1.3091 - mae: 0.8006 - val_loss: 1.2136 - val_mae: 0.7803 - 4s/epoch - 26ms/step\n",
      "Epoch 4/20\n",
      "147/147 - 4s - loss: 1.2464 - mae: 0.7835 - val_loss: 1.1764 - val_mae: 0.7679 - 4s/epoch - 27ms/step\n",
      "Epoch 5/20\n",
      "147/147 - 4s - loss: 1.1851 - mae: 0.7649 - val_loss: 1.1293 - val_mae: 0.7524 - 4s/epoch - 24ms/step\n",
      "Epoch 6/20\n",
      "147/147 - 4s - loss: 1.1541 - mae: 0.7569 - val_loss: 1.1123 - val_mae: 0.7479 - 4s/epoch - 25ms/step\n",
      "Epoch 7/20\n",
      "147/147 - 4s - loss: 1.1337 - mae: 0.7519 - val_loss: 1.0938 - val_mae: 0.7381 - 4s/epoch - 29ms/step\n",
      "Epoch 8/20\n",
      "147/147 - 4s - loss: 1.1127 - mae: 0.7458 - val_loss: 1.0900 - val_mae: 0.7434 - 4s/epoch - 29ms/step\n",
      "Epoch 9/20\n",
      "147/147 - 4s - loss: 1.0994 - mae: 0.7419 - val_loss: 1.0937 - val_mae: 0.7468 - 4s/epoch - 25ms/step\n",
      "Epoch 10/20\n",
      "147/147 - 4s - loss: 1.0858 - mae: 0.7382 - val_loss: 1.0780 - val_mae: 0.7394 - 4s/epoch - 25ms/step\n",
      "Epoch 11/20\n",
      "147/147 - 4s - loss: 1.0690 - mae: 0.7331 - val_loss: 1.0506 - val_mae: 0.7261 - 4s/epoch - 27ms/step\n",
      "Epoch 12/20\n",
      "147/147 - 4s - loss: 1.0473 - mae: 0.7261 - val_loss: 1.0383 - val_mae: 0.7263 - 4s/epoch - 28ms/step\n",
      "Epoch 13/20\n",
      "147/147 - 4s - loss: 1.0313 - mae: 0.7224 - val_loss: 1.0267 - val_mae: 0.7216 - 4s/epoch - 28ms/step\n",
      "Epoch 14/20\n",
      "147/147 - 4s - loss: 1.0142 - mae: 0.7181 - val_loss: 1.0160 - val_mae: 0.7153 - 4s/epoch - 27ms/step\n",
      "Epoch 15/20\n",
      "147/147 - 4s - loss: 0.9990 - mae: 0.7132 - val_loss: 1.0206 - val_mae: 0.7146 - 4s/epoch - 28ms/step\n",
      "Epoch 16/20\n",
      "147/147 - 4s - loss: 0.9921 - mae: 0.7112 - val_loss: 1.0021 - val_mae: 0.7116 - 4s/epoch - 25ms/step\n",
      "Epoch 17/20\n",
      "147/147 - 4s - loss: 0.9777 - mae: 0.7062 - val_loss: 0.9982 - val_mae: 0.7097 - 4s/epoch - 24ms/step\n",
      "Epoch 18/20\n",
      "147/147 - 4s - loss: 0.9711 - mae: 0.7029 - val_loss: 0.9959 - val_mae: 0.7114 - 4s/epoch - 29ms/step\n",
      "Epoch 19/20\n",
      "147/147 - 4s - loss: 0.9613 - mae: 0.7009 - val_loss: 0.9934 - val_mae: 0.7083 - 4s/epoch - 29ms/step\n",
      "Epoch 20/20\n",
      "147/147 - 4s - loss: 0.9511 - mae: 0.6977 - val_loss: 1.0119 - val_mae: 0.7164 - 4s/epoch - 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 1ms/step\n",
      "Currently training:  HepG2_tr\n",
      "Epoch 1/20\n",
      "53/53 - 2s - loss: 3.5017 - mae: 1.4597 - val_loss: 3.0994 - val_mae: 1.3713 - 2s/epoch - 47ms/step\n",
      "Epoch 2/20\n",
      "53/53 - 1s - loss: 3.0070 - mae: 1.3393 - val_loss: 2.5639 - val_mae: 1.2286 - 1s/epoch - 26ms/step\n",
      "Epoch 3/20\n",
      "53/53 - 1s - loss: 2.5212 - mae: 1.2150 - val_loss: 2.2291 - val_mae: 1.1426 - 1s/epoch - 28ms/step\n",
      "Epoch 4/20\n",
      "53/53 - 1s - loss: 2.3190 - mae: 1.1633 - val_loss: 2.1456 - val_mae: 1.1384 - 1s/epoch - 26ms/step\n",
      "Epoch 5/20\n",
      "53/53 - 1s - loss: 2.2171 - mae: 1.1355 - val_loss: 2.0568 - val_mae: 1.1087 - 1s/epoch - 25ms/step\n",
      "Epoch 6/20\n",
      "53/53 - 1s - loss: 2.1790 - mae: 1.1255 - val_loss: 2.0575 - val_mae: 1.1141 - 1s/epoch - 25ms/step\n",
      "Epoch 7/20\n",
      "53/53 - 1s - loss: 2.1164 - mae: 1.1038 - val_loss: 2.0092 - val_mae: 1.0958 - 1s/epoch - 22ms/step\n",
      "Epoch 8/20\n",
      "53/53 - 1s - loss: 2.1360 - mae: 1.1111 - val_loss: 2.0164 - val_mae: 1.1014 - 1s/epoch - 25ms/step\n",
      "Epoch 9/20\n",
      "53/53 - 1s - loss: 2.0935 - mae: 1.0980 - val_loss: 1.9463 - val_mae: 1.0667 - 1s/epoch - 23ms/step\n",
      "Epoch 10/20\n",
      "53/53 - 1s - loss: 2.0604 - mae: 1.0862 - val_loss: 2.0569 - val_mae: 1.1097 - 1s/epoch - 22ms/step\n",
      "Epoch 11/20\n",
      "53/53 - 1s - loss: 2.0576 - mae: 1.0857 - val_loss: 1.9170 - val_mae: 1.0563 - 1s/epoch - 23ms/step\n",
      "Epoch 12/20\n",
      "53/53 - 1s - loss: 2.0443 - mae: 1.0815 - val_loss: 2.0447 - val_mae: 1.1134 - 1s/epoch - 24ms/step\n",
      "Epoch 13/20\n",
      "53/53 - 1s - loss: 2.0321 - mae: 1.0787 - val_loss: 1.9354 - val_mae: 1.0620 - 1s/epoch - 23ms/step\n",
      "Epoch 14/20\n",
      "53/53 - 1s - loss: 1.9992 - mae: 1.0686 - val_loss: 1.9439 - val_mae: 1.0555 - 1s/epoch - 23ms/step\n",
      "Epoch 15/20\n",
      "53/53 - 1s - loss: 2.0030 - mae: 1.0695 - val_loss: 1.9113 - val_mae: 1.0532 - 1s/epoch - 25ms/step\n",
      "Epoch 16/20\n",
      "53/53 - 1s - loss: 1.9818 - mae: 1.0627 - val_loss: 1.8994 - val_mae: 1.0378 - 1s/epoch - 25ms/step\n",
      "Epoch 17/20\n",
      "53/53 - 1s - loss: 1.9781 - mae: 1.0626 - val_loss: 1.8997 - val_mae: 1.0475 - 1s/epoch - 26ms/step\n",
      "Epoch 18/20\n",
      "53/53 - 1s - loss: 1.9789 - mae: 1.0617 - val_loss: 1.9367 - val_mae: 1.0440 - 1s/epoch - 24ms/step\n",
      "Epoch 19/20\n",
      "53/53 - 1s - loss: 1.9863 - mae: 1.0659 - val_loss: 1.8873 - val_mae: 1.0343 - 1s/epoch - 23ms/step\n",
      "Epoch 20/20\n",
      "53/53 - 1s - loss: 1.9455 - mae: 1.0506 - val_loss: 1.9608 - val_mae: 1.0809 - 1s/epoch - 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step\n",
      "Currently training:  THLE_tr\n",
      "Epoch 1/20\n",
      "87/87 - 3s - loss: 3.2851 - mae: 1.4307 - val_loss: 2.7122 - val_mae: 1.2723 - 3s/epoch - 38ms/step\n",
      "Epoch 2/20\n",
      "87/87 - 2s - loss: 2.4398 - mae: 1.1957 - val_loss: 2.4645 - val_mae: 1.1847 - 2s/epoch - 26ms/step\n",
      "Epoch 3/20\n",
      "87/87 - 2s - loss: 2.2220 - mae: 1.1249 - val_loss: 2.2661 - val_mae: 1.1374 - 2s/epoch - 27ms/step\n",
      "Epoch 4/20\n",
      "87/87 - 2s - loss: 2.1190 - mae: 1.0942 - val_loss: 2.1607 - val_mae: 1.1068 - 2s/epoch - 25ms/step\n",
      "Epoch 5/20\n",
      "87/87 - 2s - loss: 2.0414 - mae: 1.0742 - val_loss: 2.1319 - val_mae: 1.0907 - 2s/epoch - 25ms/step\n",
      "Epoch 6/20\n",
      "87/87 - 2s - loss: 2.0437 - mae: 1.0770 - val_loss: 2.0910 - val_mae: 1.0832 - 2s/epoch - 28ms/step\n",
      "Epoch 7/20\n",
      "87/87 - 2s - loss: 1.9930 - mae: 1.0614 - val_loss: 2.0711 - val_mae: 1.0764 - 2s/epoch - 25ms/step\n",
      "Epoch 8/20\n",
      "87/87 - 2s - loss: 1.9805 - mae: 1.0588 - val_loss: 2.0926 - val_mae: 1.0925 - 2s/epoch - 26ms/step\n",
      "Epoch 9/20\n",
      "87/87 - 2s - loss: 1.9588 - mae: 1.0537 - val_loss: 2.0705 - val_mae: 1.0832 - 2s/epoch - 26ms/step\n",
      "Epoch 10/20\n",
      "87/87 - 2s - loss: 1.9409 - mae: 1.0480 - val_loss: 2.0622 - val_mae: 1.0947 - 2s/epoch - 26ms/step\n",
      "Epoch 11/20\n",
      "87/87 - 2s - loss: 1.9301 - mae: 1.0456 - val_loss: 2.0475 - val_mae: 1.0834 - 2s/epoch - 26ms/step\n",
      "Epoch 12/20\n",
      "87/87 - 2s - loss: 1.9143 - mae: 1.0412 - val_loss: 1.9987 - val_mae: 1.0573 - 2s/epoch - 26ms/step\n",
      "Epoch 13/20\n",
      "87/87 - 2s - loss: 1.9027 - mae: 1.0365 - val_loss: 1.9998 - val_mae: 1.0606 - 2s/epoch - 26ms/step\n",
      "Epoch 14/20\n",
      "87/87 - 2s - loss: 1.8938 - mae: 1.0347 - val_loss: 2.0113 - val_mae: 1.0581 - 2s/epoch - 26ms/step\n",
      "Epoch 15/20\n",
      "87/87 - 2s - loss: 1.8862 - mae: 1.0325 - val_loss: 1.9907 - val_mae: 1.0542 - 2s/epoch - 27ms/step\n",
      "Epoch 16/20\n",
      "87/87 - 2s - loss: 1.8780 - mae: 1.0294 - val_loss: 1.9902 - val_mae: 1.0573 - 2s/epoch - 26ms/step\n",
      "Epoch 17/20\n",
      "87/87 - 2s - loss: 1.8717 - mae: 1.0279 - val_loss: 1.9717 - val_mae: 1.0558 - 2s/epoch - 26ms/step\n",
      "Epoch 18/20\n",
      "87/87 - 2s - loss: 1.8652 - mae: 1.0264 - val_loss: 1.9691 - val_mae: 1.0517 - 2s/epoch - 27ms/step\n",
      "Epoch 19/20\n",
      "87/87 - 2s - loss: 1.8560 - mae: 1.0243 - val_loss: 1.9701 - val_mae: 1.0489 - 2s/epoch - 25ms/step\n",
      "Epoch 20/20\n",
      "87/87 - 2s - loss: 1.8479 - mae: 1.0216 - val_loss: 1.9712 - val_mae: 1.0554 - 2s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step\n",
      "Currently training:  Liver\n",
      "Epoch 1/20\n",
      "158/158 - 5s - loss: 1.3402 - mae: 0.9128 - val_loss: 0.9443 - val_mae: 0.7577 - 5s/epoch - 30ms/step\n",
      "Epoch 2/20\n",
      "158/158 - 4s - loss: 0.8584 - mae: 0.7047 - val_loss: 0.8135 - val_mae: 0.6910 - 4s/epoch - 23ms/step\n",
      "Epoch 3/20\n",
      "158/158 - 4s - loss: 0.7691 - mae: 0.6551 - val_loss: 0.7501 - val_mae: 0.6417 - 4s/epoch - 23ms/step\n",
      "Epoch 4/20\n",
      "158/158 - 3s - loss: 0.7412 - mae: 0.6392 - val_loss: 0.7276 - val_mae: 0.6326 - 3s/epoch - 22ms/step\n",
      "Epoch 5/20\n",
      "158/158 - 4s - loss: 0.7252 - mae: 0.6297 - val_loss: 0.7136 - val_mae: 0.6222 - 4s/epoch - 22ms/step\n",
      "Epoch 6/20\n",
      "158/158 - 4s - loss: 0.7062 - mae: 0.6195 - val_loss: 0.7258 - val_mae: 0.6284 - 4s/epoch - 23ms/step\n",
      "Epoch 7/20\n",
      "158/158 - 4s - loss: 0.6987 - mae: 0.6152 - val_loss: 0.7020 - val_mae: 0.6156 - 4s/epoch - 23ms/step\n",
      "Epoch 8/20\n",
      "158/158 - 4s - loss: 0.6907 - mae: 0.6107 - val_loss: 0.6974 - val_mae: 0.6192 - 4s/epoch - 23ms/step\n",
      "Epoch 9/20\n",
      "158/158 - 4s - loss: 0.6875 - mae: 0.6093 - val_loss: 0.6897 - val_mae: 0.6128 - 4s/epoch - 23ms/step\n",
      "Epoch 10/20\n",
      "158/158 - 4s - loss: 0.6791 - mae: 0.6046 - val_loss: 0.6790 - val_mae: 0.6061 - 4s/epoch - 23ms/step\n",
      "Epoch 11/20\n",
      "158/158 - 4s - loss: 0.6749 - mae: 0.6032 - val_loss: 0.6796 - val_mae: 0.6038 - 4s/epoch - 23ms/step\n",
      "Epoch 12/20\n",
      "158/158 - 4s - loss: 0.6701 - mae: 0.6007 - val_loss: 0.6771 - val_mae: 0.6045 - 4s/epoch - 23ms/step\n",
      "Epoch 13/20\n",
      "158/158 - 4s - loss: 0.6643 - mae: 0.5963 - val_loss: 0.6777 - val_mae: 0.6068 - 4s/epoch - 23ms/step\n",
      "Epoch 14/20\n",
      "158/158 - 4s - loss: 0.6601 - mae: 0.5945 - val_loss: 0.6896 - val_mae: 0.6112 - 4s/epoch - 23ms/step\n",
      "Epoch 15/20\n",
      "158/158 - 4s - loss: 0.6568 - mae: 0.5934 - val_loss: 0.6642 - val_mae: 0.5989 - 4s/epoch - 23ms/step\n",
      "Epoch 16/20\n",
      "158/158 - 4s - loss: 0.6537 - mae: 0.5917 - val_loss: 0.6684 - val_mae: 0.6021 - 4s/epoch - 23ms/step\n",
      "Epoch 17/20\n",
      "158/158 - 4s - loss: 0.6494 - mae: 0.5888 - val_loss: 0.6715 - val_mae: 0.5978 - 4s/epoch - 22ms/step\n",
      "Epoch 18/20\n",
      "158/158 - 4s - loss: 0.6488 - mae: 0.5887 - val_loss: 0.6681 - val_mae: 0.5991 - 4s/epoch - 23ms/step\n",
      "Epoch 19/20\n",
      "158/158 - 3s - loss: 0.6431 - mae: 0.5857 - val_loss: 0.6620 - val_mae: 0.5939 - 3s/epoch - 22ms/step\n",
      "Epoch 20/20\n",
      "158/158 - 3s - loss: 0.6385 - mae: 0.5822 - val_loss: 0.6578 - val_mae: 0.5930 - 3s/epoch - 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slou/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Modeling the six functions \n",
    "assay_testnames = ['Production', 'HEPG2_b', 'THLE_b','HEPG2_tr' , 'THLE_tr','Liver']\n",
    "\n",
    "# Initialization\n",
    "assays_models = dict()\n",
    "test_dfs = dict()\n",
    "intest_dfs = dict()\n",
    "\n",
    "# Training parameters \n",
    "batch_size = 500\n",
    "#EpochCount = 150\n",
    "EpochCount = 20 #Used for quick excusion of the Notebook; please use a higher number instead to allow proper convergence\n",
    "\n",
    "\n",
    "# Iterate over assays \n",
    "for crntAssay, cnrt_assay_testname in zip(assays,assay_testnames): \n",
    "    print('Currently training: ', crntAssay)\n",
    "    \n",
    "    #------------------------------------    \n",
    "    # Train-Test split\n",
    "    crnt_df = train_dfs[crntAssay]   \n",
    "    remove = np.isnan(crnt_df.Output) | np.isinf(crnt_df.Output)\n",
    "    crnt_df = crnt_df[~remove]\n",
    "\n",
    "    train_size = int(0.8*len(crnt_df))\n",
    "    validation_size = int(0.1*len(crnt_df))\n",
    "    train, validate, test = np.split(crnt_df.sample(frac=1), \n",
    "                                     [train_size, train_size+validation_size])\n",
    "    train = train.reset_index(drop = True)\n",
    "    validate = validate.reset_index(drop = True)\n",
    "    test = test.reset_index(drop = True)\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Encoding \n",
    "    train_x =  np.asarray([AA_hotencoding(variant) for variant in train['AA']])\n",
    "    train_y = np.array(list(train.Output))\n",
    "\n",
    "    validate_x = np.asarray([AA_hotencoding(variant) for variant in validate['AA']])\n",
    "    validate_y = np.array(list(validate.Output))\n",
    "\n",
    "    test_x = np.asarray([AA_hotencoding(variant) for variant in test['AA']])\n",
    "    test_y = np.array(list(test.Output))\n",
    "\n",
    "    #------------------------------------\n",
    "    # Fit model\n",
    "    model = parent_model()\n",
    "    model.fit(train_x, train_y, batch_size=batch_size, epochs=EpochCount, \n",
    "              validation_data=(validate_x, validate_y),verbose=2,\n",
    "              callbacks=[CustomEarlyStopping(ratio=0.85, patience=3, restore_best_weights = True)])\n",
    "\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Save model\n",
    "    ModelFileName = 'fit4function_models/fit4function_model6_fxn_'+crntAssay\n",
    "    model.save(ModelFileName+'.h5')   \n",
    "    assays_models[crntAssay] = model \n",
    "    \n",
    "    #------------------------------------  \n",
    "    # Test model \n",
    "    # Measured\n",
    "    x = np.array(test_y)\n",
    "    # Predicted\n",
    "    y = model.predict(test_x)\n",
    "    y = np.reshape(y, (1, y.shape[0]))[0]\n",
    "\n",
    "    #------------------------------------      \n",
    "    # Record performance \n",
    "    crnt_test = pd.DataFrame([x,y]).transpose()\n",
    "    crnt_test.columns =  ['Measured','Predicted']\n",
    "    intest_dfs[cnrt_assay_testname] = crnt_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d16b5f-5e43-4c1c-9297-01e60e66c09d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Source Data Files/Figure 4a.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading Performance from file \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# When plotting from Source Data Files for obtaining the manuscript figures\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m Predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mExcelFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource Data Files/Figure 4a.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m assay_testnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduction\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHEPG2_b\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTHLE_b\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHEPG2_tr\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTHLE_tr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiver\u001b[39m\u001b[38;5;124m'\u001b[39m];\n\u001b[1;32m      7\u001b[0m intest_dfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1496\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1496\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[1;32m   1497\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m   1498\u001b[0m     )\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1502\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1503\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1371\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1369\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1371\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m   1372\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1374\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1375\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Source Data Files/Figure 4a.xlsx'"
     ]
    }
   ],
   "source": [
    "# Loading Performance from file \n",
    "# When plotting from Source Data Files for obtaining the manuscript figures\n",
    "\n",
    "Predictions = pd.ExcelFile('Source Data Files/Figure 4a.xlsx')\n",
    "assay_testnames = ['Production', 'HEPG2_b', 'THLE_b','HEPG2_tr' , 'THLE_tr','Liver'];\n",
    "\n",
    "intest_dfs = dict()\n",
    "for crnt_assay in assay_testnames:\n",
    "    intest_dfs[crnt_assay] =pd.read_excel(Predictions, crnt_assay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f803be8-47d6-4fcf-8dc2-f9d9f79272c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "assays = assay_testnames.copy()\n",
    "\n",
    "titles = ['Production',\n",
    "    'HEPG2 Binding',\n",
    "    'HEPG2 Transduction',\n",
    "    'THLE Binding',\n",
    "    'THLE Transduction',\n",
    "    'Liver Biodistribution']\n",
    "\n",
    "\n",
    "# Figure Configurations\n",
    "sns.set_theme(style='ticks', font_scale=0.75, rc={\n",
    "    #'font.family': 'sans-serif',\n",
    "    'font.family': 'Arial',\n",
    "    #'font.sans-serif': ['Arial', 'DejaVu Sans'],\n",
    "    'svg.fonttype': 'none',\n",
    "    'text.usetex': False,\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'font.size': 9,\n",
    "    'axes.labelsize': 9,\n",
    "    'axes.titlesize': 9,\n",
    "    'axes.labelpad': 2,\n",
    "    'axes.linewidth': 0.5,\n",
    "    'axes.titlepad': 4,\n",
    "    'lines.linewidth': 0.5,\n",
    "    'legend.fontsize': 9,\n",
    "    'legend.title_fontsize': 9,\n",
    "    'xtick.labelsize': 7,\n",
    "    'ytick.labelsize': 7,\n",
    "    'xtick.major.size': 2,\n",
    "    'xtick.major.pad': 1,\n",
    "    'xtick.major.width': 0.5,\n",
    "    'ytick.major.size': 2,\n",
    "    'ytick.major.pad': 1,\n",
    "    'ytick.major.width': 0.5,\n",
    "    'xtick.minor.size': 2,\n",
    "    'xtick.minor.pad': 1,\n",
    "    'xtick.minor.width': 0.5,\n",
    "    'ytick.minor.size': 2,\n",
    "    'ytick.minor.pad': 1,\n",
    "    'ytick.minor.width': 0.5,\n",
    "})\n",
    "\n",
    "xlims = [\n",
    "    (-10.5, 8.5),\n",
    "    (-9.5, 9.5),\n",
    "    (-10.5, 7.5),\n",
    "    (-6.5, 7),\n",
    "    (-9, 7.5),\n",
    "    (-8, 4.5),\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 1.5), dpi=150)\n",
    "leftpad = 0.12\n",
    "rightpad = 0.03\n",
    "wspan = (1-(leftpad)-(rightpad)) / 6\n",
    "padding = wspan*0.12\n",
    "\n",
    "\n",
    "# Iterate \n",
    "for i, assay in enumerate(assays):\n",
    "    \n",
    "    # Configuration of subplots \n",
    "    gs = fig.add_gridspec(1, 1, wspace=0.0,\n",
    "        right=leftpad + ((i+1)*wspan)-padding, left=leftpad + (i*wspan)+padding\n",
    "    )\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # Data \n",
    "    df = intest_dfs[assay]    \n",
    "    x = df['Measured']\n",
    "    y = df['Predicted']\n",
    "    \n",
    "    # Preprocessing \n",
    "    remove = (np.isnan(x) | np.isnan(y) | np.isinf(x) | np.isinf(y))\n",
    "    x = x[~remove]\n",
    "    y = y[~remove]\n",
    "    \n",
    "    \n",
    "    # Kernels\n",
    "    kernel = gaussian_kde(np.vstack([\n",
    "        x.sample(n=1000, random_state=1),\n",
    "        y.sample(n=1000, random_state=1)\n",
    "    ]))\n",
    "    c = kernel(np.vstack([x, y]))\n",
    "    \n",
    "    ax.scatter(\n",
    "        x, y, c=c, s=0.5, cmap=mpl.cm.inferno,\n",
    "        rasterized=True, linewidth=0, edgecolors=None\n",
    "    )\n",
    "     \n",
    "    xlim = xlims[i]\n",
    "    ylim = xlims[i]\n",
    "    \n",
    "    ax.plot(xlim, xlim, '-r', linewidth=0.3)\n",
    "    \n",
    "    \n",
    "    # Labeling \n",
    "    xticks = np.arange(\n",
    "        np.round((xlim[0] // 2)*2),\n",
    "        np.round((xlim[1] // 2)*2) + 1, 2)\n",
    "    ax.set_xticks(xticks) \n",
    "    ax.set_yticks(xticks)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(4))\n",
    "    ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(2))\n",
    "    \n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(4))\n",
    "    ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(2))\n",
    "    \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    \n",
    "    ax.set_xlabel('Measured')\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Predicted')\n",
    "        \n",
    "    \n",
    "    # Correlation text\n",
    "    ax.text(\n",
    "        x=0.96, y=0.03, transform=ax.transAxes, ha='right', va='bottom',\n",
    "        s=r'$r$ = {:.2f}'.format(np.corrcoef(x, y)[0, 1]), fontsize=7\n",
    "    )\n",
    "    ax.set_title(assay)\n",
    "    \n",
    "    \n",
    "# Show and save \n",
    "filename = 'figures/fig4a_multifunction_modeling'\n",
    "fig.savefig('{}.png'.format(filename))\n",
    "fig.savefig('{}_600dpi.svg'.format(filename), dpi = 600)\n",
    "fig.savefig('{}_1200dpi.svg'.format(filename), dpi= 1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79465b9-7125-4fd5-96b3-398725f04326",
   "metadata": {},
   "source": [
    "------\n",
    "# MultiFunction Distributions \n",
    "\n",
    "The distribution of enrichment across variants sampled from the Uniform (3K), Fit4Function (10K), Positive Control (Fit4Function variants satisfying the six conditions), and MultiFunction libraries. The histograms are density-normalized, including non-detected variants (ND).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee4412-699b-4928-8ab1-bbe8030f660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and Meta data\n",
    "df = pd.read_csv('data/multifunction_library.csv')\n",
    "\n",
    "# Meta data\n",
    "dataset_labels = [\n",
    "    'Uniform', \n",
    "    'Fit4Function',\n",
    "    'Positive Control',\n",
    "    'MultiFunction']\n",
    "datasets = dataset_labels;\n",
    "\n",
    "cols = [\n",
    "    'Production', \n",
    "    'HepG2_bind', 'HepG2_tr',\n",
    "    'THLE_bind', 'THLE_tr',\n",
    "    'Liver']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31640be-d92e-415e-a6d1-642740503e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure Configurations\n",
    "\n",
    "xlims = [\n",
    "    (-8.5, 4.5), (-8, 6),\n",
    "    (-8, 4.5), (-8, 6.5),\n",
    "    (-8, 6), (-6, 3),\n",
    "]\n",
    "\n",
    "\n",
    "# colors = ['blue', 'orange', 'green', 'purple']\n",
    "colors = [\n",
    "    '#B3B3B3',\n",
    "    '#FF5E66',\n",
    "    '#FFA8AE',\n",
    "    '#488ABA',\n",
    "]\n",
    "\n",
    "sns.set_theme(style='ticks', font_scale=0.75, rc={\n",
    "    'font.family': 'sans-serif',\n",
    "    # 'font.sans-serif': ['Arial', 'DejaVu Sans'],\n",
    "    'svg.fonttype': 'none',\n",
    "    'text.usetex': False,\n",
    "    'pdf.fonttype': 42,\n",
    "    'ps.fonttype': 42,\n",
    "    'font.size': 9,\n",
    "    'axes.labelsize': 9,\n",
    "    'axes.titlesize': 9,\n",
    "    'axes.labelpad': 2,\n",
    "    'axes.linewidth': 0.5,\n",
    "    'axes.titlepad': 4,\n",
    "    'lines.linewidth': 0.5,\n",
    "    'legend.fontsize': 9,\n",
    "    'legend.title_fontsize': 9,\n",
    "    'xtick.major.size': 2,\n",
    "    'xtick.major.pad': 2,\n",
    "    'xtick.major.width': 0.5,\n",
    "    'ytick.major.size': 2,\n",
    "    'ytick.major.pad': 2,\n",
    "    'ytick.major.width': 0.5,\n",
    "    'xtick.minor.size': 2,\n",
    "    'xtick.minor.pad': 2,\n",
    "    'xtick.minor.width': 0.5,\n",
    "    'ytick.minor.size': 2,\n",
    "    'ytick.minor.pad': 2,\n",
    "    'ytick.minor.width': 0.5,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da8fd2-26f0-4161-a779-27a5681eb440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "# More configurations \n",
    "fig = plt.figure(figsize=(6, 2), dpi=150)\n",
    "\n",
    "leftpad = 0.16\n",
    "rightpad = 0.03\n",
    "wspan = (1-(leftpad)-(rightpad)) / len(cols)\n",
    "padding = wspan*0.12\n",
    "\n",
    "# Iterate over assays \n",
    "for c, col in enumerate(cols):\n",
    "    \n",
    "    # Subplot configurations \n",
    "    gs = fig.add_gridspec(len(datasets), 1, hspace=-0.8, wspace=0.0,\n",
    "                          # width_ratios=[2, 1], \n",
    "                          bottom=0.15,\n",
    "                          left=leftpad + (c*wspan)+padding, right=leftpad + ((c+1)*wspan)-padding)\n",
    "    xlim = xlims[c]\n",
    "    xticks = np.arange(\n",
    "        np.round((xlim[0] // 2)*2),\n",
    "        np.round((xlim[1] // 2)*2) + 1,\n",
    "        2\n",
    "    )\n",
    "    bins = np.linspace(xlim[0], xlim[1], 60)\n",
    "    bins = np.append(-100, bins)\n",
    "\n",
    "    # Iterate over the four sets \n",
    "    for i, dataset in enumerate(datasets):  \n",
    "        \n",
    "        # Histogram\n",
    "        ax = fig.add_subplot(gs[i, 0])\n",
    "        x = df.loc[df['Label'] == dataset, col]\n",
    "        nd = (x <= 1e-5)\n",
    "        x[x <= 0] = 1e-5\n",
    "        x = np.log2(x)\n",
    "        freq,_,_ = ax.hist(x, bins=bins, color=colors[i], edgecolor='none', \n",
    "                rasterized=True, density=True, alpha=0.6)\n",
    "        ax.step(bins[1:], freq, color='#888')\n",
    "\n",
    "        if c == 0:\n",
    "            ax.text(-0.2, 0, dataset_labels[i], color=colors[i], fontsize=9,\n",
    "                    ha='right', va='bottom', transform=ax.transAxes)\n",
    "        \n",
    "        if c == len(cols)-1 and i == 0:\n",
    "            ax.yaxis.set_label_position('right')\n",
    "            ax.set_ylabel('Density', loc='bottom', rotation=270, labelpad=12.)\n",
    "\n",
    "        # Transparent background and coloring \n",
    "        ax.patch.set_alpha(0)\n",
    "\n",
    "        ax.set_xticks(xticks)\n",
    "        if i == i == len(datasets) - 1:\n",
    "            ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(4))\n",
    "            ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(2))\n",
    "        else:\n",
    "            ax.xaxis.set_major_locator(mpl.ticker.NullLocator())\n",
    "            ax.xaxis.set_minor_locator(mpl.ticker.NullLocator())\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim([0, 1.0])\n",
    "\n",
    "        # ['left', 'right', 'bottom', 'top']\n",
    "        for spine in ax.spines.keys():\n",
    "            ax.spines[spine].set_visible(False)\n",
    "            \n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['bottom'].set_linewidth(0.5)\n",
    "        ax.spines['bottom'].set_color('#CCC')\n",
    "\n",
    "        # Labeling \n",
    "        if i == len(datasets) - 1:\n",
    "            ax.spines['bottom'].set_color('#444')\n",
    "            ax.set_xlabel(col)            \n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_xticklabels([])\n",
    "            \n",
    "        rect_width = 0.15\n",
    "        rect_height = 0.2\n",
    "        ax.add_patch(mpl.patches.Rectangle(\n",
    "            ((-1 * rect_width) - 0.02, 0), rect_width, rect_height,\n",
    "            transform=ax.transAxes, clip_on=False, facecolor=colors[i], alpha=0.5\n",
    "        ))\n",
    "        ax.text((-1 * (rect_width / 2))-0.01, rect_height/2, '{:.1f}'.format((nd.sum() / len(x)) * 100), \n",
    "                fontsize=5.5, transform=ax.transAxes, rotation=90, ha='center', va='center', color='#444')\n",
    "        if i == 3:\n",
    "            ax.text((-1 * (rect_width / 2))-0.02, -0.04, 'ND', transform=ax.transAxes, ha='center', va='top',\n",
    "                   fontsize=6)\n",
    "            \n",
    "# Show and save  \n",
    "filename = 'figures/fig4b_multifunction_distributions' \n",
    "fig.savefig(filename + '.png', transparent=True, dpi=200)\n",
    "fig.savefig('{}_600dpi.svg'.format(filename), dpi = 600)\n",
    "fig.savefig('{}_1200dpi.svg'.format(filename), dpi= 1200)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
